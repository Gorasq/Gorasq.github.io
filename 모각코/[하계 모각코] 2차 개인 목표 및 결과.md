# 2차 활동 개인 목표

소리 데이터 전처리 방법에 대해서 알아보는 것이 오늘의 목표이다. 

## 소리 데이터 저장 형식

연속적인 아날로그 신호를 디지털 신호로 저장하기 위해 초 당 n번으로 쪼개어 저장한다. 저장하는 과정은 양자화와 인코딩으로 나눌 수 있다. 양자화는 아날로그 신호를 디지털 신호로 바꾸기 위해 근사값을 구하는 과정이고 인코딩은 근사값을 2진법 비트로 저장하는 과정이다. 쪼개는 정도를 'Sampling rate'라고 한다. 인간의 가청 주파수는 20,000Hz이지만 데이터 손실을 최소화 하고자 [나이퀴스트 이론](https://ralasun.github.io/signal%20analysis/2021/07/01/nyq/)에 따라 40,000Hz 이상이고 신호 왜곡을 최소화 하고자 44100Hz,48000Hz등 40,000Hz이상의 Sampling rate를 사용한다. 

소리 데이터를 사용하고자 할 때, librosa 라이브러리를 사용할 수 있다. 
[librosa 공식 웹사이트](https://librosa.org/doc/latest/index.html)

소리는 다양한 주파수들이 간섭하여 합쳐진  

##  MFCC : Mel-Frequency Cepstral Coefficient

오디오 신호의 대표적(고유적) 특징을 나타낼 수 있는 수치를 MFCC라고 한다. 
소리 데이터를 수십ms 간격의 여러 개의 프레임으로 나눈다.(Framing) 프레임들은 다음 과정 진행 후 다시 합쳐지는 과정에서 프레임의 좌우 경계값에서 신호가 불연속해져 실제 신호와 달라지는 문제점이 있어 Window function 을 이용하여 경계를 0으로 만들어 연속으로 만들거나 프레임간 겹치는 부분을 만들어 이 문제를 해결할 수 있다. 이후 프레임 각각에 대해 [FFT(Fast Fourier Transformation, 고속푸리에변환)](https://youtu.be/nmgFG7PUHfo?si=sOtZB9JqmvuUlQPb)를 진행한다.  이 과정을 통해 소리 데이터가 어떤 주파수들로 이뤄져 있는지 알 수 있고 이 주파수들을 바탕으로 스펙트럼(Spectrum ; frequency-magnitude 그래프}을 알아 낼 수 있다. 이후 Mel-Filter bank라는 필터를 스펙트럼에 적용시킨다. 이 필터를 적용하면 사람들의 청각에 민감한 1000Hz 이하의 진동수에 대해서는 Linear scale로, 이상의 진동수에 대해서는 log  scale변환하는데 Mel scale triangular filter 등의 필터를 적용하여 변환한다. 이 과정을 통해 Mel spectrum을 구할 수 있다. 이후 스펙트럼에 log값을 취한  DCT(Discrete Cosine Transformation)를 통해 코사인 함수들의 합으로 표현해 내고 이 중 13번째 까지의 함수의 계수를 소리의 특징들로 사용한다. 

스펙트럼은 진동수-데시벨 그래프로도 표현될 수 있는데, 이때 피크가 어디서 나타나는지 파악하여 어떤 진동수들에서 대표적 특징을 보이는지 알아낼 수 있다. 이때, 피크들을 Formants라고 부르고, Formats와 그래프의 극소점을 이은 곡선을 이용하여 소리의 대표적 특징을 분석하는 것을 cepstral analysis라고 한다. 



## 참고자료
[서봉성](https://velog.io/@sbs524/%EC%9D%8C%EC%84%B1-%EC%9D%B8%EC%8B%9D-%EA%B8%B0%EC%B4%88-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-%EC%A2%85%EA%B2%B0-1)
[현토리](https://hyunlee103.tistory.com/54)
[Bright Dev Archive](https://brightwon.tistory.com/11)
